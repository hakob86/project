import os
import json
import subprocess
from threading import Thread
from flask import Flask, request, jsonify, render_template, redirect, url_for
from flask_migrate import Migrate
from users import db
from users.models import AutoParseConfig, Job
import logging
from flask import flash


app = Flask(__name__)
app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///database.db'
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –±–∞–∑—ã –∏ –º–∏–≥—Ä–∞—Ü–∏–π
db.init_app(app)
migrate = Migrate(app, db)

class JobParserManager:
    def __init__(self, base_path, topic, min_budget, max_budget, region, category, keywords, project_type, experience, duration, posted_date):
        self.base_path = base_path
        self.topic = topic
        self.min_budget = min_budget
        self.max_budget = max_budget
        self.region = region
        self.category = category
        self.keywords = keywords
        self.project_type = project_type
        self.experience = experience
        self.duration = duration
        self.posted_date = posted_date

    def run_all(self):
        jobs = []
        try:
            def run_parser(script_name):
                script_path = os.path.join(os.path.dirname(__file__), "parsers", script_name)
                logger.info(f"‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ {script_name} c —Ç–µ–º–æ–π: {self.topic}")
                result = subprocess.run([
                    "node", script_path, self.topic, self.min_budget, self.max_budget, self.region,
                    self.category, self.keywords, self.project_type, self.experience, self.duration, self.posted_date
                ], capture_output=True, text=True)
                logger.info(f"‚ÑπÔ∏è STDOUT {script_name} ‚Üí {result.stdout}")
                logger.error(f"‚ö†Ô∏è STDERR {script_name} ‚Üí {result.stderr}")

            upwork_thread = Thread(target=run_parser, args=("puppeteer_upwork.js",))
            guru_thread = Thread(target=run_parser, args=("puppeteer_guru.js",))
            upwork_thread.start()
            guru_thread.start()
            upwork_thread.join()
            guru_thread.join()

            for fname in ["upwork.json", "guru.json"]:
                fpath = os.path.join(self.base_path, fname)
                if os.path.exists(fpath):
                    with open(fpath, encoding='utf-8') as f:
                        data = json.load(f)
                        logger.info(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –∑–∞–¥–∞—á –∏–∑ {fname}")
                        jobs.extend(data)
                else:
                    logger.warning(f"‚ùå –§–∞–π–ª {fpath} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø–∞—Ä—Å–µ—Ä–æ–≤")
            raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞: {str(e)}")
        return jobs

class JobFilter:
    def __init__(self, min_budget):
        self.min_budget = float(min_budget)
        self.stop_words = ["scam", "crypto", "adult"]
        self.links_seen = set()

    def is_relevant(self, job):
        keywords = ["–±–æ—Ç", "–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è", "scraper", "parser"]
        return any(word in job.get("description", "").lower() for word in keywords)

    def extract_budget(self, job):
        try:
            if isinstance(job.get("budget"), (int, float)):
                return float(job["budget"])
            text = job.get("budget") or job.get("description", "")
            for token in text.split():
                if token.replace("$", "").replace(",", "").isdigit():
                    return float(token.replace("$", "").replace(",", ""))
        except:
            pass
        return 0

    def filter_jobs(self, jobs):
        filtered = []
        for job in jobs:
            if not job.get("description") or not job.get("link"):
                continue
            if job.get("link") in self.links_seen:
                continue
            self.links_seen.add(job.get("link"))
            if not job.get("client_payment_verified", True):
                continue
            if job.get("client_hires", 0) < 1:
                continue
            if job.get("client_proposals", 0) > 30:
                continue
            if any(word in job.get("description", "").lower() for word in self.stop_words):
                continue
            if not self.is_relevant(job):
                continue
            if self.extract_budget(job) < self.min_budget:
                continue
            filtered.append(job)
        logger.info(f"‚úÖ –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å: {len(filtered)} –∑–∞–¥–∞—á")
        return filtered

class JobSaver:
    def __init__(self, user_id):
        self.user_id = user_id

    def save(self, jobs):
        for job in jobs:
            if not Job.query.filter_by(link=job['link']).first():
                new_job = Job(
                    title=job.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
                    description=job.get("description", ""),
                    budget=job.get("budget", ""),
                    link=job.get("link"),
                    status="new",
                    user_id=self.user_id
                )
                db.session.add(new_job)
        try:
            db.session.commit()
            logger.info("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
        except Exception as e:
            db.session.rollback()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –ë–î: {e}")
            raise

@app.route('/')
def index():
    jobs = Job.query.order_by(Job.id.desc()).limit(20).all()
    return render_template('index.html', jobs=jobs)

@app.route('/search', methods=['POST'])
def search():
    query = request.form.get("query", "").strip()
    if not query:
        flash("–ü–∞—Ä—Å–µ—Ä –ø—Ä–µ–≤—ã—Å–∏–ª –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏", "error")
        return redirect(url_for('index'))

    # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
    parts = query.split()
    topic = " ".join(parts[:-1]) if parts and parts[-1].isdigit() else query
    min_budget = parts[-1] if parts and parts[-1].isdigit() else "0"
    max_budget = "9999999"
    region = ""

    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä
    try:
        cmd = [
            "node",
            os.path.join("parsers", "puppeteer_guru.js"),
            topic,
            str(min_budget),
            str(max_budget),
            region
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=1000)

        if result.stderr:
            logger.error(f"‚ö†Ô∏è STDERR puppeteer_guru.js ‚Üí {result.stderr}")
        if result.stdout:
            logger.info(f"‚ÑπÔ∏è STDOUT puppeteer_guru.js ‚Üí {result.stdout}")

    except subprocess.TimeoutExpired:
        logger.error("‚è∞ –ü–∞—Ä—Å–µ—Ä –ø—Ä–µ–≤—ã—Å–∏–ª –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏")
        return jsonify({"error": "–ü–∞—Ä—Å–µ—Ä –ø—Ä–µ–≤—ã—Å–∏–ª –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏"}), 500
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø–∞—Ä—Å–µ—Ä–∞")
        return jsonify({"error": str(e)}), 500

    # –ß—Ç–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    try:
        with open(os.path.join("results", "guru.json"), "r", encoding="utf-8") as f:
            jobs = json.load(f)
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è guru.json")
        return jsonify({"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–µ—Ä–∞"}), 500

    return render_template("index.html", jobs=jobs)

@app.route('/add', methods=['POST'])
def add():
    data = request.get_json()
    logger.info(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ /add: {data}")
    return jsonify({"status": "ok"})

if __name__ == '__main__':
    with app.app_context():
        db.create_all()
    app.run(debug=True)
